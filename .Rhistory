## Results visualization:
library(ggplot2)  # version: ggplot2_3.4.4
library(ggridges) #version: ggridges_0.5.6
library(RColorBrewer) #version: RColorBrewer_1.1-3
library(ggrepel) # version: ggrepel_0.9.5
To begin, we reformat data so that each possible answer becomes a separate binary question (One Hot encoding). In preparing the data, we used the `dummy_cols()` utility from the `fastdummies` package.  Finally, we rename the new binary dataframe as `Y` to underscore that this is the observed data that we will be modeling. Please ensure that the `dataPath` variable is adjusted for your local file structure.
## MODIFICATION FOR SYNTHETIC DATA
datapath <- "../data/"
ebdatsynth <- read.csv(file=paste0(datapath, 'synth_questions.csv'))
colnames(ebdatsynth)
## drop "X" and "unnamed" which are just row counters
ebdatsynth[,c("X", "Unnamed..0")] <- NULL
## Convert numeric ordinal responses to factors
ebdatsub <- lapply(ebdatsynth[,], factor) ## that's a list now
## converts the list back into a dataframe:
ebbinary <- fastDummies::dummy_cols(.data=ebdatsub,
remove_selected_columns=TRUE)
Y <- ebbinary ## data
## remove the .data that dummy_cols adds to the column names
colnames(Y) <- gsub(".data.", '', colnames(Y))
## remove the data objects:
rm(ebdatsub)
rm(ebdatsynth)
load(file=paste0(datapath, 'mcodes.rda'))
## Only keep M-Codes with loadings or outcomes:
MCodes$encoding <- rowSums(abs(MCodes[,4:9]))
MCodes <- MCodes[which(MCodes$encoding > 0),]
print(colnames(MCodes))
print(head(MCodes))
MCodes[which(MCodes$`D1-Culture threat`==1),]$QMap
MCodes[which(MCodes$`D2-ReligionThreat`==1),]$QMap
## Load on Economic Threat
MCodes[which(MCodes$`D3-Economic Threat`==1),]$QMap
MCodes[which(MCodes$`D4-HealthThreat`==1),]$QMap
paste(MCodes[which(MCodes$`D1-Culture threat`==1),]$QMap)
# Load on Culture Threat:
paste(MCodes[which(MCodes$`D1-Culture threat`==1),]$QMap, sep = " + ")
# Load on Culture Threat:
paste(MCodes[which(MCodes$`D1-Culture threat`==1),]$QMap, sep = " + ", collapse = TRUE)
# Load on Culture Threat:
paste(MCodes[which(MCodes$`D1-Culture threat`==1),]$QMap, sep = " + ", collapse = "+")
MCodes[which(MCodes$`D3-Economic Threat`==1),]$QMap
paste(MCodes[which(MCodes$`D1-Culture threat`==1),]$QMap, collapse = " + ")
rm(list = ls())
setwd("~/Dropbox/DominosPaper/Dominos-Code/code2022/")
library(dplyr)
library(ggplot2)
library(igraph)
## Format data:
## (Reconstruct the initial network statistics for the networks)
## Create initial centrality measure
## and number of rounds to entry into group
process <- function(filename, netstype){
load(filename)
netstype= netstype ## code network types
exit= data.frame()
entry= data.frame()
alldat = data.frame()
## Reconstruct initial network statistics
for(r in 1:length(node.traj)){
print(r)
tmp = bind_rows(node.traj[[r]])
## fallthrough if the node.traj object doesn't
## have 11 columns [indicates a corner case]
if(!dim(tmp)[2]==11){
print(paste0("skipping round ", r, "for dim incompatibility"))
next}
## Recreate initial centrality values
## for group members (g nodes) & recruits (r nodes)
g1 <-  graph_from_edgelist(
as.matrix(bN[[r]]$edgelist[grepl(pattern="g",
x=bN[[r]]$edgelist$from),
c("from", "to")]))
gcent <- round(eigen_centrality(g1)$vector, 2)
r1 <-  graph_from_edgelist(
as.matrix(bN[[r]]$edgelist[grepl(pattern="r",
x=bN[[r]]$edgelist$from),
c("from", "to")]))
rcent <- round(eigen_centrality(r1)$vector, 2)
## Graph-level centralization:
rcent.eigen <- centr_eigen(r1)$centralization
rcent.degree <- centr_degree(r1)$centralization
gcent.eigen <- centr_eigen(g1)$centralization
gcent.degree <- centr_degree(g1)$centralization
## move to a dataframe:
init.centrality <- as.data.frame(c(gcent, rcent))
init.centrality$nodeID <- as.character(rownames(init.centrality))
init.centrality$ggraph.ecent <- round(gcent.eigen, 3)
init.centrality$ggraph.degcent <- round(gcent.degree, 3)
init.centrality$rgraph.ecent <-   round(rcent.eigen, 3)
init.centrality$rgraph.degcent <- round(rcent.degree, 3)
colnames(init.centrality)[1:2] <- c("initialcent", "nodeID")
init.centrality$whichSim <- r
## get an initial metric centralization score:
## for recruits and for group members:
## Simulation data
## Observe that I'm throwing away a lot of data in the second index;
##need to figure out what
to.work.with <- node.traj[[r]] ## list of node attributes by round
tww <- bind_rows(to.work.with,## list to dataframe
.id = "column_label")
tww2 <- left_join(tww, ## add in the centrality info
init.centrality,
by=c("nodeID"= "nodeID"))
tww2$structure = netstype ## TWW2 is one round
alldat = rbind(alldat, tww2) ## alldat is nodes for all rounds
} ## end node info reconstruction
## dignostics, if desired
##plot(density(tww2$ggraph.ecent)) ## uniform
##plot(density(tww2$rgraph.ecent)) ## uniform
##table(tww2$iteration)
##table(tww2$round)
##table(tww2$nodeID) ##  63 per node, except g17(?)
##table(tww2$shockpercent) ## 10-90
## clean up into a dataframe:
dev.alldat <-alldat %>%
group_by(iteration, shockpercent, round) %>%
count(type) %>%
mutate(total.nodes = sum(n)) %>%
mutate(rep.percent = round(n/total.nodes, 2))#
## add the graph centralization info:
## list the graph attribute columns:
## get the columns with "graph" in the name:
## (these are graph attributes, and I don't feel like typing all)
gas <-colnames(alldat)[grep(colnames(alldat), pattern="graph")]
graph.atts <- c("iteration", "shockpercent", "round",
gas)
## add original network centrality attributes:
dev.alldat2 <- dev.alldat %>%
left_join(unique(alldat[,graph.atts]),
by=c("iteration" = "iteration", ##reminder: iteration = which simulated network
"shockpercent" = "shockpercent",
"round" = "round"))
## Add the network configuration:
dev.alldat2$nettype <- netstype
return(dev.alldat2)
}
erpa_nets <- process(filename="ER-PASims.Rdata",
netstype="ER-PA")
View(erpa_nets)
gg2 <- ggplot(data = er_pa,
aes(y = rep.percent,
x = round))+
geom_boxplot(aes(group= round), outlier.alpha=.1)+
facet_grid(type ~shockpercent)+
theme_bw()+
scale_x_discrete(limits=c(paste0(1:7)))+
theme(legend.position="bottom")
gg2 <- ggplot(data =erpa_nets,
aes(y = rep.percent,
x = round))+
geom_boxplot(aes(group= round), outlier.alpha=.1)+
facet_grid(type ~shockpercent)+
theme_bw()+
scale_x_discrete(limits=c(paste0(1:7)))+
theme(legend.position="bottom")
gg2
devtools::check(IRT)
devtools::check(IRTM)
getwd()
setwd("~/Dropbox/IRTM-Pkg/IRTM/")
ls
devtools::document()
devtools::document()
devtools::check(IRTM)
devtools::check()
armadillo_version(single)
armadillo_version()
library(IRTM)
armadillo_version(single)
devtools::check()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::check()
devtools::check_win()
devtools::check_win_release()
devtools::document()
devtools::check()
devtools::check_rhub()
devtools::release()
R CMD check
maintainer(IRTM)
maintainer()
library(IRTM)
maintainer()
maintainer("IRTM"")
maintainer("IRTM")
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
## Data prep:
library(tidyverse) # version: tidyverse_2.0.0
library(dplyr) #version: dplyr_1.1.4
library(stats) # version: stats4
library(fastDummies) # version: fastDummies_1.7.3
library(reshape2) #version: reshape2_1.4.4
## IRT-M estimation:
#devtools::install_github("dasiegel/IRT-M")
library(IRTM) #version 1.00
## Results visualization:
library(ggplot2)  # version: ggplot2_3.4.4
library(ggridges) #version: ggridges_0.5.6
library(RColorBrewer) #version: RColorBrewer_1.1-3
library(ggrepel) # version: ggrepel_0.9.5
## MODIFICATION FOR SYNTHETIC DATA
datapath <- "../data/"
ebdatsynth <- read.csv(file=paste0(datapath, 'synth_questions.csv'))
colnames(ebdatsynth)
## drop "X" and "unnamed" which are just row counters
ebdatsynth[,c("X", "Unnamed..0")] <- NULL
## Convert numeric ordinal responses to factors
ebdatsub <- lapply(ebdatsynth[,], factor) ## that's a list now
## converts the list back into a dataframe:
ebbinary <- dummy_cols(.data=ebdatsub,
remove_selected_columns=TRUE)
Y <- ebbinary ## data
## remove the .data that dummy_cols adds to the column names
colnames(Y) <- gsub(".data.", '', colnames(Y))
## remove the data objects:
rm(ebdatsub)
rm(ebdatsynth)
datapath <- "../data/"
ebdatsynth <- read.csv(file=paste0(datapath, 'synth_questions.csv'))
colnames(ebdatsynth)
## drop "X" and "unnamed" which are just row counters
ebdatsynth[,c("X", "Unnamed..0")] <- NULL
## Convert numeric ordinal responses to factors
ebdatsub <- lapply(ebdatsynth[,], factor) ## that's a list now
## converts the list back into a dataframe:
ebbinary <- dummy_cols(.data=ebdatsub,
remove_selected_columns=TRUE)
Y <- ebbinary ## data
## remove the .data that dummy_cols adds to the column names
colnames(Y) <- gsub(".data.", '', colnames(Y))
## remove the data objects:
rm(ebdatsub)
rm(ebdatsynth)
load(file=paste0(datapath, 'mcodes.rda'))
## Only keep M-Codes with loadings or outcomes:
MCodes$encoding <- rowSums(abs(MCodes[,4:9]))
MCodes <- MCodes[which(MCodes$encoding > 0),]
## Produce a K-coded questions x R-responses data frame:
mcolumns <- c("QMap", "D1-Culture threat",
"D2-ReligionThreat",
"D3-Economic Threat",
"D4-HealthThreat",
"O1-OutcomeSupportImmigration", "O2-OutcomeSupportEU")
combine <- MCodes[,mcolumns] %>% ## question codes and loadings
inner_join(
Y %>%
t() %>%
as.data.frame(stringsAsFactors = FALSE) %>%
type_convert() %>%
rownames_to_column(var = "question"),
by = c("QMap" = "question"  )
)
dim(M)
dim(combine)
View(combine)
View(combine)
#datapath <- "../data/"
data("synth_questions")
#ebdatsynth <- read.csv(file=paste0(datapath, 'synth_questions.csv'))
colnames(ebdatsynth)
datapath <- "../data/"
ebdatsynth <- read.csv(file=paste0(datapath, 'synth_questions.csv'))
getwd()
datapath <- "../data/"
datapath <- "./data/"
ebdatsynth <- read.csv(file=paste0(datapath, 'synth_questions.csv'))
save(ebdatsynth, file= "synth_questions.rda")
synthidvs <- read.csv(file=paste0(datapath, 'synth_idvs.csv'))
save(synthidvs, file= "synth_idvs.rda")
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
data("synth_questions")
colnames(ebdatsynth)
datapath <- "./data/"
ebdatsynth <- read.csv(file=paste0(datapath, 'synth_questions.csv'))
ebdatsynth[,c("X", "Unnamed..0")] <- NULL
save(ebdatsynth, file= "synth_questions.rda")
data("synth_questions")
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
data("synth_questions")
data("synth_questions")
data("synth_questions")
library(tidyverse) # version: tidyverse_2.0.0
library(dplyr) #version: dplyr_1.1.4
library(stats) # version: stats4
library(fastDummies) # version: fastDummies_1.7.3
library(reshape2) #version: reshape2_1.4.4
## IRT-M estimation:
#devtools::install_github("dasiegel/IRT-M")
library(IRTM) #version 1.00
library(ggplot2)  # version: ggplot2_3.4.4
library(ggridges) #version: ggridges_0.5.6
library(RColorBrewer) #version: RColorBrewer_1.1-3
library(ggrepel) # version: ggrepel_0.9.5
data("synth_questions")
data("synth_questions.rda")
datapath <- "./data/"
ebdatsynth <- read.csv(file=paste0(datapath, 'synth_questions.csv'))
ebdatsynth[,c("X", "Unnamed..0")] <- NULL
usethis::use_data(synth_questions)
usethis::use_data(synth_questions, overwrite=TRUE)
data("synth_questions")
usethis::use_data(synthidvs, overwrite=TRUE)
synthidvs <- read.csv(file=paste0(datapath, 'synth_idvs.csv'))
datapath <- "./data/"
synth_questions <- read.csv(file=paste0(datapath, 'synth_questions.csv'))
ebdatsynth[,c("X", "Unnamed..0")] <- NULL
usethis::use_data(synth_questions, overwrite=TRUE)
synth_idvs <- read.csv(file=paste0(datapath, 'synth_idvs.csv'))
usethis::use_data(synth_idvs, overwrite=TRUE)
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
## Data prep:
library(tidyverse) # version: tidyverse_2.0.0
library(dplyr) #version: dplyr_1.1.4
library(stats) # version: stats4
library(fastDummies) # version: fastDummies_1.7.3
library(reshape2) #version: reshape2_1.4.4
## IRT-M estimation:
#devtools::install_github("dasiegel/IRT-M")
library(IRTM) #version 1.00
## Results visualization:
library(ggplot2)  # version: ggplot2_3.4.4
library(ggridges) #version: ggridges_0.5.6
library(RColorBrewer) #version: RColorBrewer_1.1-3
library(ggrepel) # version: ggrepel_0.9.5
data("synth_questions")
data("synth_questions.")
data("synth_questions")
force(synth_questions)
data("synth_questions")
colnames(synth_questions)
ebdatsub <- lapply(synth_questions[,], factor) ## that's a list now
## converts the list back into a dataframe:
ebbinary <- dummy_cols(.data=ebdatsub,
remove_selected_columns=TRUE)
Y <- ebbinary ## data
## remove the .data that dummy_cols adds to the column names
colnames(Y) <- gsub(".data.", '', colnames(Y))
rm(ebdatsub)
rm(ebdatsynth)
## load idvs:
load("synth_idvs")
## load idvs:
data("synth_idvs")
colnames(synth_idvs) ## note that d63 is class qa6a are media trust
thetas <- cbind(avgthetas, synth_idvs)
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
#load(file=paste0(datapath, 'mcodes.rda'))
data("mcodes"")
#load(file=paste0(datapath, 'mcodes.rda'))
data("mcodes")
#load(file=paste0(datapath, 'mcodes.rda'))
data("mcodes")
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
## Data prep:
library(tidyverse) # version: tidyverse_2.0.0
library(dplyr) #version: dplyr_1.1.4
library(stats) # version: stats4
library(fastDummies) # version: fastDummies_1.7.3
library(reshape2) #version: reshape2_1.4.4
## IRT-M estimation:
#devtools::install_github("dasiegel/IRT-M")
library(IRTM) #version 1.00
## Results visualization:
library(ggplot2)  # version: ggplot2_3.4.4
library(ggridges) #version: ggridges_0.5.6
library(RColorBrewer) #version: RColorBrewer_1.1-3
library(ggrepel) # version: ggrepel_0.9.5
data("synth_questions")
colnames(synth_questions)
## Convert numeric ordinal responses to factors
ebdatsub <- lapply(synth_questions[,], factor) ## that's a list now
## converts the list back into a dataframe:
ebbinary <- dummy_cols(.data=ebdatsub,
remove_selected_columns=TRUE)
Y <- ebbinary ## data
## remove the .data that dummy_cols adds to the column names
colnames(Y) <- gsub(".data.", '', colnames(Y))
## remove the data objects:
rm(ebdatsub)
rm(synth_questions)
#load(file=paste0(datapath, 'mcodes.rda'))
data("mcodes")
## Only keep M-Codes with loadings or outcomes:
MCodes$encoding <- rowSums(abs(MCodes[,4:9]))
MCodes <- MCodes[which(MCodes$encoding > 0),]
## Produce a K-coded questions x R-responses data frame:
mcolumns <- c("QMap", "D1-Culture threat",
"D2-ReligionThreat",
"D3-Economic Threat",
"D4-HealthThreat",
"O1-OutcomeSupportImmigration", "O2-OutcomeSupportEU")
combine <- MCodes[,mcolumns] %>% ## question codes and loadings
inner_join(
Y %>%
t() %>%
as.data.frame(stringsAsFactors = FALSE) %>%
type_convert() %>%
rownames_to_column(var = "question"),
by = c("QMap" = "question"  )
)
d <- 6 #number of coded dimensions
loadings <- 2:7 ## columns in combine object with the loadings
M <- array(NA, c(d, d, nrow(combine)))
for (i in 1:nrow(combine)) {
M[,,i] <- diag(combine[i,
loadings])
}
data("synth_questions")
colnames(synth_questions)
ebdatsub <- lapply(synth_questions[,], factor) ## that's a list now
ebbinary <- dummy_cols(.data=ebdatsub,
remove_selected_columns=TRUE)
ebbinary <- dummy_cols(.data=ebdatsub,
remove_selected_columns=TRUE)
Y <- ebbinary ## data
## remove the .data that dummy_cols adds to the column names
colnames(Y) <- gsub(".data.", '', colnames(Y))
## remove the .data that dummy_cols adds to the column names
colnames(Y) <- gsub(".data.", '', colnames(Y))
View(ebbinary)
View(synth_questions)
View(synth_questions)
synth_questions <- read_csv("..data/synth_questions.csv")
synth_questions <- read.csv("..data/synth_questions.csv")
synth_questions <- read.csv("../data/synth_questions.csv")
getwd()
synth_questions <- read.csv("./data/synth_questions.csv")
View(synth_questions)
synth_questions$X <- NULL
synth_questions$Unnamed..0 <- NULL
save(synth_questions, "./data/synth_questions.rda")
save(synth_questions,file= "./data/synth_questions.rda")
###
library(IRTM)
data("synth_questions")
save(synth_questions,file= "./data/synth_questions.rda", lazy=FALSE)
###
library(IRTM)
data("synth_questions")
colnames(synth_questions)
synth_questions <- read.csv("./data/synth_questions.csv")
synth_questions$X <- NULL
synth_questions$Unnamed..0 <- NULL
usethis::use_data("synth_questions")
#save(synth_questions,file= "./data/synth_questions.rda", lazy=FALSE)
usethis::use_data("synth_questions", overwrite=TRUE)
#save(synth_questions,file= "./data/synth_questions.rda", lazy=FALSE)
usethis::use_data(synth_questions, overwrite=TRUE)
library(IRTM)
data("synth_questions")
colnames(synth_questions)
dim(synth_qustions)
dim(synth_questions)
synth_questions <- as.data.frame(synth_questions)
synth_questions <- read.csv("./data/synth_questions.csv")
synth_questions$X <- NULL
synth_questions$Unnamed..0 <- NULL
synth_questions <- as.data.frame(synth_questions)
# Test that it looks correct
str(synth_questions)
save(synth_questions, file = "./data/synth_questions.rda", compress = "xz")
###
library(IRTM)
data("synth_questions")
colnames(synth_questions)
load("./data/synth_questions.rda")
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
## Data prep:
library(tidyverse) # version: tidyverse_2.0.0
library(dplyr) #version: dplyr_1.1.4
library(stats) # version: stats4
library(fastDummies) # version: fastDummies_1.7.3
library(reshape2) #version: reshape2_1.4.4
## IRT-M estimation:
#devtools::install_github("dasiegel/IRT-M")
library(IRTM) #version 1.00
## Results visualization:
library(ggplot2)  # version: ggplot2_3.4.4
library(ggridges) #version: ggridges_0.5.6
library(RColorBrewer) #version: RColorBrewer_1.1-3
library(ggrepel) # version: ggrepel_0.9.5
synth_questions <- NULL  # Initialize to avoid R CMD check notes
datapath <- file.path(system.file(package = "IRTM"), "data", "synth_questions.rda")
load(datapath)
datapath <- file.path(system.file(package = "IRTM"), "data", "synth_questions.rda")
load(datapath)
load(system.file("data", "synth_questions.rda", package = "IRTM"))
