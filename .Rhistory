synth_questions$X <- NULL
synth_questions$Unnamed..0 <- NULL
save(synth_questions, "./data/synth_questions.rda")
save(synth_questions,file= "./data/synth_questions.rda")
###
library(IRTM)
data("synth_questions")
save(synth_questions,file= "./data/synth_questions.rda", lazy=FALSE)
###
library(IRTM)
data("synth_questions")
colnames(synth_questions)
synth_questions <- read.csv("./data/synth_questions.csv")
synth_questions$X <- NULL
synth_questions$Unnamed..0 <- NULL
usethis::use_data("synth_questions")
#save(synth_questions,file= "./data/synth_questions.rda", lazy=FALSE)
usethis::use_data("synth_questions", overwrite=TRUE)
#save(synth_questions,file= "./data/synth_questions.rda", lazy=FALSE)
usethis::use_data(synth_questions, overwrite=TRUE)
library(IRTM)
data("synth_questions")
colnames(synth_questions)
dim(synth_qustions)
dim(synth_questions)
synth_questions <- as.data.frame(synth_questions)
synth_questions <- read.csv("./data/synth_questions.csv")
synth_questions$X <- NULL
synth_questions$Unnamed..0 <- NULL
synth_questions <- as.data.frame(synth_questions)
# Test that it looks correct
str(synth_questions)
save(synth_questions, file = "./data/synth_questions.rda", compress = "xz")
###
library(IRTM)
data("synth_questions")
colnames(synth_questions)
load("./data/synth_questions.rda")
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
## Data prep:
library(tidyverse) # version: tidyverse_2.0.0
library(dplyr) #version: dplyr_1.1.4
library(stats) # version: stats4
library(fastDummies) # version: fastDummies_1.7.3
library(reshape2) #version: reshape2_1.4.4
## IRT-M estimation:
#devtools::install_github("dasiegel/IRT-M")
library(IRTM) #version 1.00
## Results visualization:
library(ggplot2)  # version: ggplot2_3.4.4
library(ggridges) #version: ggridges_0.5.6
library(RColorBrewer) #version: RColorBrewer_1.1-3
library(ggrepel) # version: ggrepel_0.9.5
synth_questions <- NULL  # Initialize to avoid R CMD check notes
datapath <- file.path(system.file(package = "IRTM"), "data", "synth_questions.rda")
load(datapath)
datapath <- file.path(system.file(package = "IRTM"), "data", "synth_questions.rda")
load(datapath)
load(system.file("data", "synth_questions.rda", package = "IRTM"))
getwd()
setwd("~/Desktop/Alex_Turkey_Maths/")
devtools::install("IRTM", build_vignettes = TRUE)
devtools::install("dasiegel/IRT-M", build_vignettes = TRUE)
devtools::install_github("dasiegel/IRT-M", build_vignettes = TRUE)
setwd("~/IRT-M")
?if
()
?ifelse
?mse
?list
?ab
?abs
install.packages("spelling")
quarto check
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
load("./vdata/synth_questions.rda")
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
## Data prep:
library(tidyverse) # version: tidyverse_2.0.0
library(dplyr) #version: dplyr_1.1.4
library(stats) # version: stats4
library(fastDummies) # version: fastDummies_1.7.3
library(reshape2) #version: reshape2_1.4.4
## IRT-M estimation:
#devtools::install_github("dasiegel/IRT-M")
library(IRTM) #version 1.00
## Results visualization:
library(ggplot2)  # version: ggplot2_3.4.4
library(ggridges) #version: ggridges_0.5.6
library(RColorBrewer) #version: RColorBrewer_1.1-3
library(ggrepel) # version: ggrepel_0.9.5
synth_questions <- NULL  # Initialize to avoid R CMD check notes
load("./vdata/synth_questions.rda")
## Convert numeric ordinal responses to factors
ebdatsub <- lapply(ebdatsynth[,], factor) ## that's a list now
## converts the list back into a dataframe:
ebbinary <- dummy_cols(.data=ebdatsub,
remove_selected_columns=TRUE)
Y <- ebbinary ## data
## remove the .data that dummy_cols adds to the column names
colnames(Y) <- gsub(".data.", '', colnames(Y))
## remove the data objects:
rm(ebdatsub)
rm(ebdatsynth)
load('./vdata/mcodes.rda')
## Only keep M-Codes with loadings or outcomes:
MCodes$encoding <- rowSums(abs(MCodes[,4:9]))
MCodes <- MCodes[which(MCodes$encoding > 0),]
## Produce a K-coded questions x R-responses data frame:
mcolumns <- c("QMap", "D1-Culture threat",
"D2-ReligionThreat",
"D3-Economic Threat",
"D4-HealthThreat",
"O1-OutcomeSupportImmigration", "O2-OutcomeSupportEU")
combine <- MCodes[,mcolumns] %>% ## question codes and loadings
inner_join(
Y %>%
t() %>%
as.data.frame(stringsAsFactors = FALSE) %>%
type_convert() %>%
rownames_to_column(var = "question"),
by = c("QMap" = "question"  )
)
d <- 6 #number of coded dimensions
loadings <- 2:7 ## columns in combine object with the loadings
M <- array(NA, c(d, d, nrow(combine)))
for (i in 1:nrow(combine)) {
M[,,i] <- diag(combine[i,
loadings])
}
View(combine)
?ncol
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
synth_questions <- NULL  # Initialize to avoid R CMD check notes
load("./vdata/synth_questions.rda")
## Convert numeric ordinal responses to factors
ebdatsub <- lapply(ebdatsynth[,], factor) ## that's a list now
## converts the list back into a dataframe:
ebbinary <- dummy_cols(.data=ebdatsub,
remove_selected_columns=TRUE)
## Data prep:
library(tidyverse) # version: tidyverse_2.0.0
library(dplyr) #version: dplyr_1.1.4
library(stats) # version: stats4
library(fastDummies) # version: fastDummies_1.7.3
library(reshape2) #version: reshape2_1.4.4
## IRT-M estimation:
#devtools::install_github("dasiegel/IRT-M")
library(IRTM) #version 1.00
## Results visualization:
library(ggplot2)  # version: ggplot2_3.4.4
library(ggridges) #version: ggridges_0.5.6
library(RColorBrewer) #version: RColorBrewer_1.1-3
library(ggrepel) # version: ggrepel_0.9.5
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
synth_questions <- NULL  # Initialize to avoid R CMD check notes
load("./vdata/synth_questions.rda")
## Convert numeric ordinal responses to factors
ebdatsub <- lapply(ebdatsynth[,], factor) ## that's a list now
## converts the list back into a dataframe:
ebbinary <- dummy_cols(.data=ebdatsub,
remove_selected_columns=TRUE)
Y_in <- ebbinary ## data
## remove the .data that dummy_cols adds to the column names
colnames(Y) <- gsub(".data.", '', colnames(Y))
synth_questions <- NULL  # Initialize to avoid R CMD check notes
load("./vdata/synth_questions.rda")
## Convert numeric ordinal responses to factors
ebdatsub <- lapply(ebdatsynth[,], factor) ## that's a list now
## converts the list back into a dataframe:
ebbinary <- dummy_cols(.data=ebdatsub,
remove_selected_columns=TRUE)
Y_in <- ebbinary ## data
## remove the .data that dummy_cols adds to the column names
colnames(Y_in) <- gsub(".data.", '', colnames(Y))
synth_questions <- NULL  # Initialize to avoid R CMD check notes
load("./vdata/synth_questions.rda")
## Convert numeric ordinal responses to factors
ebdatsub <- lapply(ebdatsynth[,], factor) ## that's a list now
## converts the list back into a dataframe:
ebbinary <- dummy_cols(.data=ebdatsub,
remove_selected_columns=TRUE)
Y_in <- ebbinary ## data
## remove the .data that dummy_cols adds to the column names
colnames(Y_in) <- gsub(".data.", '', colnames(Y_in))
## remove the data objects:
rm(ebdatsub)
rm(ebdatsynth)
View(ebbinary)
View(Y_in)
View(ebbinary)
rm(ebbinary)
load('./vdata/mcodes.rda')
## Only keep M-Codes with loadings or outcomes:
MCodes$encoding <- rowSums(abs(MCodes[,4:9]))
MCodes <- MCodes[which(MCodes$encoding > 0),]
View(MCodes)
synth_questions <- NULL  # Initialize to avoid R CMD check notes
load("./vdata/synth_questions.rda")
## Convert numeric ordinal responses to factors
ebdatsub <- lapply(ebdatsynth[,], factor) ## that's a list now
## converts the list back into a dataframe:
ebbinary <- dummy_cols(.data=ebdatsub,
remove_selected_columns=TRUE)
Y <- ebbinary ## data
## remove the .data that dummy_cols adds to the column names
colnames(Y) <- gsub(".data.", '', colnames(Y))
## remove the data objects:
rm(ebdatsub)
rm(ebdatsynth)
rm(ebbinary)
load('./vdata/mcodes.rda')
View(MCodes)
View(Y)
## Only keep M-Codes with loadings or outcomes:
MCodes$encoding <- rowSums(abs(MCodes[,4:9]))
MCodes <- MCodes[which(MCodes$encoding > 0),]
columns_to_keep <- as.character(MCodes[[2]])
Y_in <- Y[, columns_to_keep, drop = FALSE]
colnames(Y)
setdiff(columns_to_keep, colnames(Y))
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
## Data prep:
library(tidyverse) # version: tidyverse_2.0.0
library(dplyr) #version: dplyr_1.1.4
library(stats) # version: stats4
library(fastDummies) # version: fastDummies_1.7.3
library(reshape2) #version: reshape2_1.4.4
## IRT-M estimation:
#devtools::install_github("dasiegel/IRT-M")
library(IRTM) #version 1.00
## Results visualization:
library(ggplot2)  # version: ggplot2_3.4.4
library(ggridges) #version: ggridges_0.5.6
library(RColorBrewer) #version: RColorBrewer_1.1-3
library(ggrepel) # version: ggrepel_0.9.5
load("./vdata/synth_questions.rda")
View(ebdatsynth)
ebdatsub <- lapply(ebdatsynth[,], factor) ## that's a list now
?dummy_cols
View(ebdatsub)
?dim
mcolumns <- c("QMap", "D1-Culture threat",
"D2-ReligionThreat",
"D3-Economic Threat",
"D4-HealthThreat",
"O1-OutcomeSupportImmigration", "O2-OutcomeSupportEU")
Mo<-MCodes[,mcolumns]
#Next check to ensure that M has d+1 dimensions if not NULL.
if (!is.null(Mo) && dim(Mo)[2]!=(6+1)) {
stop("The number of latent dimensions does not match the number coded in M_matrix.")
}
#Next check to ensure that M has d+1 dimensions if not NULL.
if (!is.null(Mo) && dim(Mo)[2]!=(6+1)) {
print("The number of latent dimensions does not match the number coded in M_matrix.")
}
#Next check to ensure that M has d+1 dimensions if not NULL.
if (!is.null(Mo) && dim(Mo)[2]!=(4+1)) {
print("The number of latent dimensions does not match the number coded in M_matrix.")
}
d=6
#Next check to ensure that M has d+1 dimensions if not NULL.
if (!is.null(Mo) && dim(Mo)[2]!=(d+1)) {
print("The number of latent dimensions does not match the number coded in M_matrix.")
}
?numeric(0)
?irt_m
?get_lambdas
View(MCodes)
View(MCodes)
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
## Data prep:
library(tidyverse) # version: tidyverse_2.0.0
library(dplyr) #version: dplyr_1.1.4
library(stats) # version: stats4
library(fastDummies) # version: fastDummies_1.7.3
library(reshape2) #version: reshape2_1.4.4
## IRT-M estimation:
#devtools::install_github("dasiegel/IRT-M")
library(IRTM) #version 1.00
## Results visualization:
library(ggplot2)  # version: ggplot2_3.4.4
library(ggridges) #version: ggridges_0.5.6
library(RColorBrewer) #version: RColorBrewer_1.1-3
library(ggrepel) # version: ggrepel_0.9.5
synth_questions <- NULL  # Initialize to avoid R CMD check notes
load("./vdata/synth_questions.rda")
## Convert numeric ordinal responses to factors
ebdatsub <- lapply(ebdatsynth[,], factor) ## that's a list now
## converts the list back into a dataframe:
Y <- dummy_cols(.data=ebdatsub,
remove_selected_columns=TRUE)
## remove the .data that dummy_cols adds to the column names
colnames(Y) <- gsub(".data.", '', colnames(Y))
## remove the data objects:
rm(ebdatsub)
rm(ebdatsynth)
load('./vdata/mcodes.rda')
## Only keep M-Codes with loadings or outcomes:
MCodes$encoding <- rowSums(abs(MCodes[,4:9]))
MCodes <- MCodes[which(MCodes$encoding > 0),]
## Produce a K-coded questions x R-responses data frame:
d <- 6 #number of coded dimensions
mcolumns <- c("QMap", "D1-Culture threat",
"D2-ReligionThreat",
"D3-Economic Threat",
"D4-HealthThreat",
"O1-OutcomeSupportImmigration", "O2-OutcomeSupportEU")
combine <- MCodes[,mcolumns] %>% ## question codes and loadings
inner_join(
Y %>%
t() %>%
as.data.frame(stringsAsFactors = FALSE) %>%
type_convert() %>%
rownames_to_column(var = "question"),
by = c("QMap" = "question"  )
)
M_matrix <- as.data.frame(combine[, 1:(d+1)])
#Reverse the earlier transposition of the observations:
Y_in <- combine[, (d+2):ncol(combine)]%>%
t() %>%
as.data.frame()
Y_in <- as.data.frame(sapply(Y_in, as.numeric))
## Take the question names and
## convert to column names
question <- combine[,1] %>%
as.data.frame()
colnames(Y_in) <- question[,1]
rm(combine)
rm(question)
View(M_matrix)
View(Y_in)
d=6
irt <- irt_m(Y_in = Y_in, d = d, M_matrix = M_matrix, nsamp = 1000, nburn=20, thin=1)
avgthetas <- theta_av(irt$theta)
## load idvs:
load("./vdata/synth_idvs.rda")
thetas <- cbind(avgthetas, synthidvs)
## Rename columns for readability:
colnames(thetas)[1:6] <- paste0("Theta", 1:6)
colnames(thetas)[colnames(thetas)=="qb7_2"] <- "MoreBorderControl"
## Cast into factors:
thetas$mediatrust <- as.factor(thetas$mediatrust)
thetas$class <- as.factor(thetas$class)
thetas$polorient <- as.factor(thetas$polorient)
head(thetas)
#Compute correlation matrix of latent dimensions
theta_names <- c("Culture Threat", "Religion Threat", "Economic Threat", "Health Threat", "Support Immigration", "Support EU")
theta_corr <- dim_corr(irt$Sigma, theta_names)
#Compute correlation matrix of latent dimensions
theta_names <- c("Culture Threat", "Religion Threat", "Economic Threat", "Health Threat", "Support Immigration", "Support EU")
theta_corr <- dim_corr(irt$Sigma, theta_names)
theta_corr
library(ggplot2) #version: ggplot2_3.4.4
library(ggridges) #version: ggridges_0.5.6
library(RColorBrewer) #version: RColorBrewer_1.1-3
library(dplyr) #version: dplyr_1.1.4
library(ggrepel) # version: ggrepel_0.9.5
library(reshape2) #version: reshape2_1.4.4
## Rename for interpretability:
## Mapping:
## Theta1-Culture threat
## Theta2-ReligionThreat
## Theta3-Economic Threat
## Theta4-HealthThreat
## Theta5-OutcomeSupportImmigration
## Theta6-OutcomeSupportEU
colnames(thetas)[1:6] <-  recode(colnames(thetas)[1:6],
"Theta1" = "Culture Threat",
"Theta2" = "Religion Threat",
"Theta3" = "Economic Threat",
"Theta4" = "Health Threat",
"Theta5" = "Support Immigration",
"Theta6" = "Support EU")
ggbase <- irt_vis(d = d, T_out = thetas, sub_name = NULL, out_file = "ebirtm-synth.png")
ggmt <- irt_vis(d = d, T_out = thetas, sub_name = "mediatrust", out_file = "theta-media-synth.png")
#Explore item loadings
lambdas <- get_lambdas(irt$lambda, theta_names, MCodes[2], MCodes[3])
?MCodes[2]
MCodes[2]
#Explore item loadings
lambdas <- get_lambdas(irt$lambda, theta_names, M_matrix$QMap)
#Explore item loadings
lambdas <- get_lambdas(irt$lambda, item_names = M_matrix$QMap, dim_names = theta_names)
average_lambdas <- lambdas[[1]]
highest_lambdas <- lambdas[[2]]
average_lambdas
highest_lambdas
sn <- question %>%
left_join(MCodes[,c("QMap", "SubstantiveNotes")],
by = "QMap",
multiple = "all")
#Extract relevant substantive notes and create data frame with them and item codes
filtered_MCodes <- MCodes[MCodes[[2]] %in% M_matrix$QMap, , drop = FALSE]
M_df <- data.frame(QMap = M_matrix$QMap, sn = filtered_MCodes[[3]])
#Explore item loadings
lambdas <- get_lambdas(irt$lambda, item_names = M_df$QMap, dim_names = M_df$sn)
#Extract relevant substantive notes and create data frame with them and item codes
filtered_MCodes <- MCodes[MCodes[[2]] %in% M_matrix$QMap, , drop = FALSE]
M_df <- data.frame(QMap = M_matrix$QMap, sn = filtered_MCodes[[3]])
#Explore item loadings
lambdas <- get_lambdas(irt$lambda, item_names = M_df$QMap, dim_names = theta_names, item_elab = M_df$sn)
average_lambdas <- lambdas[[1]]
highest_lambdas <- lambdas[[2]]
average_lambdas
highest_lambdas
?irt_m
??irt_m
library(tidyverse) # version: tidyverse_2.0.0
library(dplyr) #version: dplyr_1.1.4
library(stats) # version: stats4
library(fastDummies) # version: fastDummies_1.7.3
library(reshape2) #version: reshape2_1.4.4
## IRT-M estimation:
#devtools::install_github("dasiegel/IRT-M")
library(IRTM) #version 1.00
## Results visualization:
library(ggplot2)  # version: ggplot2_3.4.4
library(ggridges) #version: ggridges_0.5.6
library(RColorBrewer) #version: RColorBrewer_1.1-3
library(ggrepel) # version: ggrepel_0.9.5
## Take as input two csv files, one for the input data, and the second for the constraints coding
setwd("C:/Interrep")
#setwd("~/Documents/RStuff")
Y_0 <- read.csv("cmps_irtm.csv")
M_0_3 <- read.csv("mcode_3.csv")
M_0_4 <- read.csv("mcode_4.csv")
M_0_1 <- read.csv("mcode_1.csv")
irt_3 <- irt_m(Y_0, 3, M_0_3, nsamp=10000, nburn=2000, thin = 10)
irt_3 <- irt_m(Y_0, 3, M_0_3, nsamp=1000, nburn=1000, thin = 1)
irt_4 <- irt_m(Y_0, 4, M_0_4, nsamp=1000, nburn=1000, thin = 1)
irt_1 <- irt_m(Y_0, 1, M_0_1, nsamp=1000, nburn=1000, thin = 1)
## Get average thetas
avgthetas_3 <- theta_av(irt_3$theta)
avgthetas_4 <- theta_av(irt_4$theta)
avgthetas_1 <- theta_av(irt_1$theta)
## Get independent and dependent variables
cmps_dv<-read.csv("cmps_dv.csv")
thetas_3 <- cbind(avgthetas_3, cmps_dv)
thetas_4 <- cbind(avgthetas_4, cmps_dv)
thetas_1 <- cbind(avgthetas_1, cmps_dv)
## Rename columns for readability:
colnames(thetas_3)[1:3] <- c("Behavior", "Identity", "ActiveHarm")
colnames(thetas_3)[4:21] <- c("White", "HispanicLatino", "Black", "Asian",
"MiddleEasternArab", "NativeAmerican",
"Other", "Female", "Male", "Other",
"BelongStrong", "BelongModerately",
"BelongSlightly", "BelongNotatAll",
"OutsiderStrong", "OutsiderModerately",
"OutsiderSlightly", "OutsiderNotatAll")
colnames(thetas_3)[22:24] <- c("Race", "Race2", "Gender")
colnames(thetas_4)[1:4] <- c("Behavior", "Identity", "ActiveHarm", "PassiveHarm")
colnames(thetas_4)[5:22] <- c("White", "HispanicLatino", "Black", "Asian",
"MiddleEasternArab", "NativeAmerican",
"Other", "Female", "Male", "Other",
"BelongStrong", "BelongModerately",
"BelongSlightly", "BelongNotatAll",
"OutsiderStrong", "OutsiderModerately",
"OutsiderSlightly", "OutsiderNotatAll")
colnames(thetas_4)[23:25] <- c("Race", "Race2", "Gender")
colnames(thetas_1)[1] <- "Exposure"
colnames(thetas_1)[2:19] <- c("White", "HispanicLatino", "Black", "Asian",
"MiddleEasternArab", "NativeAmerican",
"Other", "Female", "Male", "Other",
"BelongStrong", "BelongModerately",
"BelongSlightly", "BelongNotatAll",
"OutsiderStrong", "OutsiderModerately",
"OutsiderSlightly", "OutsiderNotatAll")
colnames(thetas_1)[20:22] <- c("Race", "Race2", "Gender")
## Aggregate Plots of Thetas
ggbase_3 <- irt_vis(3, thetas_3, out_file = "thetas_base_3.png")
ggbase_4 <- irt_vis(4, thetas_4, out_file = "thetas_base_4.png")
ggbase_1 <- irt_vis(1, thetas_1, out_file = "thetas_base_1.png")
## Disaggregated Plots by race/ethnicity and gender
gg_race_3 <- irt_vis(3, thetas_3, "Race", out_file = "theta-race-3.png")
gg_race2_3 <- irt_vis(3, thetas_3, "Race2", out_file = "theta-race2-3.png")
gg_gender_3 <- irt_vis(3, thetas_3, "Gender", out_file = "theta-gender-3.png")
gg_race_4 <- irt_vis(4, thetas_4, "Race", out_file = "theta-race-4.png")
gg_race2_4 <- irt_vis(4, thetas_4, "Race2", out_file = "theta-race2-4.png")
gg_gender_4 <- irt_vis(4, thetas_4, "Gender", out_file = "theta-gender-4.png")
gg_race_1 <- irt_vis(1, thetas_1, "Race", out_file = "theta-race-1.png")
gg_race2_1 <- irt_vis(1, thetas_1, "Race2", out_file = "theta-race2-1.png")
gg_gender_1 <- irt_vis(1, thetas_1, "Gender", out_file = "theta-gender-1.png")
## Analyze loadings
lambdas_3 <- get_lambdas(irt_3$lambda, M_0_3$QMap, colnames(M_0_3)[2:4])
lambdas_4 <- get_lambdas(irt_4$lambda, M_0_4$QMap, colnames(M_0_4)[2:5])
lambdas_1 <- get_lambdas(irt_1$lambda, M_0_1$QMap, colnames(M_0_3)[2:2])
## Correlations between latent dimensions
theta_corr_3 <- dim_corr(irt_3$Sigma, colnames(M_0_3)[2:4])
theta_corr_3 <- dim_corr(irt_3$Sigma, colnames(M_0_3)[2:4])
theta_corr_4 <- dim_corr(irt_4$Sigma, colnames(M_0_4)[2:5])
